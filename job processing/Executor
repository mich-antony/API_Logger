I would like to design a multi-tenanted remote code execution engine. The request will be submitted from Reat UI to FASTAPI based REST API, the REST API will prepare and submit the request to Kafka Topic named 'Job'. A single 'Job' request contains collection individual 'Job Items' so these are added to another Topic called 'Job Item' There will be a consumer which will read the 'Job', extract the 'Job Item' and add it into 'Job Item' topic. There will be a consumer group to read the 'Job Item' and process the 'Job Item'. The Job Item will get executed by execution engine. There are multiple Tenant and each Job and Job Item specify in which tenant the job item will get executed. Each tenant has one Job execution engine, but each execution engine can have multiple instances of it to scale the processing. Basically the execution engine instances form the consumer group for Job Item, so each instance have one consumer. 

For audit tables, instead of a single audit for everything, create separate audit tables. Also have some kind of traceability in the flow, so can track from request to all the to the end.
I would like to audit log each step or stage of the flow, can we implement it including table schema and python code? So I can know the flow. Also, for the correlation, can I use traceparent id approach?

I would like to design database schema for the above description with auditing for entire process. Use best practices and design patterns which should support enterprise standards. Explain the tables and code with sample data and use case scenarios. Also, provide Python based code to add/remove/update these tables including auditing tables. Use best practices and design patterns which should support enterprise standards.

Note that, one of the tenants is using a standalone Linux server and another one using Open shift Container Platform. So the instance creation of the execution engine will be different

